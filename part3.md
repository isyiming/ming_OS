# mingOS
### 系统的虚拟内存实现
### 配合《深入理解计算机系统》食用

---------------
### part3 内核堆的实现

在频繁的开辟内存和释放内存后，内存空间中一定存在一些断断续续的碎片区域。或许足够大的区域我们还不能叫它碎片，碎片指的是那种明明有空间，但是由于我们想要申请的内存空间较大，没办法利用的零碎空间。
我们就用一个链表来管理这些碎片空间吧。

我们把内存空间中的连续片段都用一个结构体来描述它们的状态。连续片段指的是，比如一段8kb的内存空间已经被使用了，紧接着的12k没有被使用。这两段我们都用一个结构体来表述。
```c
#define KHEAP_START 0x20000000 //堆起始地址 25MB处 0x20000000

typedef
struct header {
	struct header * prev; 	// 前后内存块管理结构指针
	struct header * next;
	uint32_t allocated : 1;	// 该内存块是否已经被申请
	uint32_t length : 31; 	// 当前内存块的长度
} header_t;
```
那就要有一个全新的kmalloc了
```c
void *kmalloc(uint32_t len)
{
	// 所有申请的内存长度加上管理头的长度,因为在内存申请和释放的时候要通过该结构去管理
	len += sizeof(header_t);

	header_t * cur_header = heap_first;
	header_t * prev_header = 0;

	while (cur_header) {
		// 如果当前内存块没有被申请过而且长度大于待申请的块
		if (cur_header->allocated == 0 && cur_header->length >= len) {
			// 按照当前长度切割内存
			split_chunk(cur_header, len);
			cur_header->allocated = 1;
			// 返回的时候必须将指针挪到管理结构之后
			return (void *)((uint32_t)cur_header + sizeof(header_t));
		}
		// 逐次推移指针
		prev_header = cur_header;
		cur_header = cur_header->next;
	}

	uint32_t chunk_start;

	// 第一次执行该函数则初始化内存块起始位置
	// 之后根据当前指针加上申请的长度即可
	if (prev_header) {
		chunk_start = (uint32_t)prev_header + prev_header->length;
	} else {
		chunk_start = KHEAP_START;
		heap_first = (header_t * )chunk_start;
	}

	// 检查是否需要申请内存页
	alloc_chunk(chunk_start, len);
	cur_header = (header_t * )chunk_start;
	cur_header->prev = prev_header;
	cur_header->next = 0;
	cur_header->allocated = 1;
	cur_header->length = len;

	if (prev_header) {
		prev_header->next = cur_header;
	}

	return (void*)(chunk_start + sizeof(header_t));
}

```
Linux系统内核所占用的内存空间地址应该是3GB～4GB的部分，实现的方式比较复杂而且麻烦。链接脚本中规定了代码段是从0x1000开始的，可是想要让内核直接加载到3GB以上的地址空间是不行的。因为我们现在的BOOTSET程序加载内核的方式是在16位模式下加载bin文件到主存。然后切换到32位模式后，跳转到0x1000处的kernel_entry函数，kernel_entry函数调用kernel_main()。那么为什么不能直接把内核代码段在链接的时候就设置成0xC0000000？是个好想法。我也尝试了下，但是是不行的，其实最开始的时候我就想过我的程序为啥要从0x1000开始，我设置成1MB开始不好吗？确实不行。这样就跳不到kernel_entry的位置处了。

这就需要在内核被引导后再做一次页表和页目录的迁移。
不过我为了简单，就不这样做了。直接把堆的

我们把全部的内存块的header_t串联起来组成一个链表，在开辟内存的时候，只需要沿着这条链表遍历就好，如果遇到一个未被使用的块大小大于我们想要申请的大小，那就在链表中插入一个节点，并且将这个块对应的header_t改写。这样这个链表就可以完美的表述当前内存的使用情况了。
而释放内存对应的链表操作就是删减合并节点。当然也可能是插入节点。另外如果遇到一段未被使用的内存空间的大小超过了完整的一页，就可以将这一页内存释放掉了，对应的就是对页表的操作。而发现遍历整个链表之后，还是没有足够的内存空间，那就需要申请新的内存页。

这里的实现方式确实很简单，其实真正的堆管理要考虑的情况多得多。

1. 在extend和init的时候都需要对块的起始地址进3bit（）的对齐，和页面对齐的时候一样，一个不整齐的地址访问，低效复杂，有些cpu可能就不支持。

2. 合并区块的问题
  在释放掉一个内存块后是否要立刻合并呢？如果我们有一些操作是频繁的申请和释放一个对象很多次，这种现象应该在程序运行时非常常见。
  太明显了，要是我们在一个固定的时间间隔才统一对链表进行节点合并，那么堆的管理会高效的多，可以减少很多重复操作。
  但是，我们又不能保证这种现象一直存在，如果程序需要不断的申请内存，而还没有到节点合并的时候，那就只能申请新的页，等合并区块后，就会产生更多的碎片。

3. 区块合并的进一步优化
  现在的程序是用了一个双向链表保存了每个区块的长度，其实就可以对应CSAPP中的隐式空闲链表。
  其实当某个区块不是空闲的时候，我们是不需要它的两个指针的。要是再有一个链表，只记录空闲链表就好了。这样在区块合并的时候，就不用对全部区块进行遍历了。非常节省时间。
  那这时候我们也不需要一个双向链表了。这就是CSAPP中的边界标记。但是最开始分配区块的时候又是一个和块总数线性相关的时间了。

4. 链表的排序策略
  对堆的区块链表进行排序，是不错的内存管理办法。
  1）LIFO（后进先出）新释放的区块放在链表的开头，那么分配器就会首先检查最近使用过的块，那么释放的时候，它就可以被立刻释放。如果我们也使用边界标记，对空闲区块单独建立一个链表，那么合并也可以是常数时间。
  2）按照地址顺序维护链表，那这个链表就是最普通的链表了。合并和分配都是遍历一遍整个链表。

5. 由于每一个区块都是对8bit进行对齐过的，那么最后3个bit就都是0了，这个时候可以作为有效位表示当前区块是否被占用。这就是隐式空闲链表。显式链表是普通的链表，一个真正存在的数据结构。就像我的程序中那样的，但是我没有用最后一个bit作为有效位。

6. 伙伴系统
  首先限定我们分配的区块大小都是2的整数次幂
  一句话概括就是，每分配一个块，都会有一个和它大小相同而且紧接着它的空闲区块被插入空闲链表中。
  这样每个区块的伙伴的地址和它只会差一bit。这样合并的时候会非常快，因为对应的空闲区块非常容易找到。

总之，堆的作用就是在分页的基础上更好的提供分配内存的功能，尽量减少内存碎片的出现。其实Linux使用的是伙伴算法，但是我现在的时间真的不多了，最近一直忙着改论文，发现自己都没有时间准确秋招，真的太慌了。


3.虚拟内存作为缓存的工具 磁盘作为主存的缓存
  我们将磁盘中某一段区域也分割称4kb大小的页，将主存中不活跃的页暂存在磁盘中，主存中保存这活跃的页。这样可以最大限度的利用有限的主存，让更多进程时刻调用的页保持在主存中。

  这里要注意下，由于磁盘的构造。他随机读取一个字节的代价非常高昂。而且往往在使用一段信息的时候，它的上下文也是有可能在下一时刻被使用。数据库的B-tree就是这样设计的嘛。所以对磁盘一次仅仅读取一个字节不合理。所以我们一般将页设计成4kb～2MB。

  我们认为设定了一个概念，虚拟内存。这个虚拟内存被组织为一个存在磁盘中的数组，数组的每一个字节都有一个唯一的虚拟地址，作为数组的索引。
  磁盘上的这个数组，活跃部分被缓存到主存中。
  这个数组被分割成块，主存和磁盘之间的传输最小单位就是块。实际上就是虚拟内存的页。
  虚拟内存系统将虚拟内存分割为虚拟页，每一页大小是P字节。对应物理内存也得分成物理页，这是方便我们载入页到实际的主存中。
  那么虚拟内存的全部页可以分为三种情况：
    1）未分配的
    2）缓存的
    3）未缓存的

6.缺页
  缺页异常，当CPU引用某一页的VP3，但是在页表PTE3中发现它的有效位是0。说明这一页没有加载到DRAM中，那就需要从磁盘中加载这一页。
  于是触发系统缺页异常，异常处理程序会在主存中选择一个牺牲页VP4。如果该牺牲页已经被修改了(和磁盘中的相比)，那就将它复制回磁盘。
  接下来内核会从磁盘中复制VP3到内存中的pp3中。这就完成了缺页的处理。
  页从磁盘和主存之间的传送叫做页面调度，一般都是用按需调度，只有在不明中的时候才调度。

7.程序的局部性保证了缺页异常不会经常发生，从而保证了虚拟内存的高效率。
  虚拟内存是用低速的磁盘作为主存的拓展，如果频繁的发生页面调度，那么肯定会拉低程序的运行效率。
  但是进程在执行过程中并不是频繁的跳来跳去的，因为cpu只能执行当前代码段，所以它访问的虚拟内存的页也是有限的。
  如果我我们不引入虚拟内存，那么多进程的内存管理实在是太麻烦了。程序执行效率肯定一定会更低，除非你有比虚拟内存更好的办法。

  程序运行时，短时间内总是趋向于在一个较小的活动页面集合上工作，这个集合叫做工作集，或者常驻集合。
  如果工作集超过了物理内存的大小，那程序将处于一种“抖动状态”，页面将频繁的调度。
  这时候就效率太低了，是不是程序设计的太不合理了，一次读取了太大的数据。

8.虚拟内存作为内存管理工具带来的好处
  1）简化了链接：因为在虚拟内存中，每个进程有自己独立的内存空间，这个内存空间的真实地址由系统和CPU的内存管理单元翻译。
  所以链接的时候不需要考虑程序在主存中的真实地址是多少，只要将每个程序按照相同的格式翻译好就可以了。
  比如，链接器对不同的程序，总是可以设置成代码段从0x400000开始，静态数据段跟在代码段之后，然后是堆，从高地址往下是栈。
  这样的一致性对于链接器来讲实在是太方便了，我们终于看到系统带来的巨大好处。
  它将内存地址这种具体的硬件抽象，对于上层的应用而言，不用针对设备具体设计程序。
  2）简化加载：Linux系统加载器加载可执行文件的时候，只需要为代码段和数据段分配虚拟页，把他们标记为无效的（未缓存的）就可以了。这时候他们还在磁盘上，只有系统调用该页的时候，产生了缺页异常，系统才会加载该页到主存。这样看来，还是系统帮我们解决了和硬件打交道的工作，我们编写的程序只需要满足系统指定的规则就可以了。
  将一组连续虚拟页映射到一个文件的任意位置，叫做内存映射。Linux提供一个mmap的系统调用，允许应用程序自己做内存映射。
  3）简化共享：如果多个进程都需要调用一些系统代码，系统调用。那么操作系统就可以将不同进程中的适当虚拟页映射到相同的物理页上（它们共同调用的那些系统代码段）。
  4）简化内存分配：




13.内存映射
  Linux系统将一个虚拟内存区域与一个磁盘上的对象关联
  虚拟内存区域可以映射到两种类型的文件中的一种：
    1）Linux文件系统中的普通文件，这种情况下只是将PTE更改了，但是磁盘上的文件没有真正复制到主存中，只有cpu访问该文件触发缺页异常后，才载入主存。
    2）匿名文件，映射到匿名文件时，这个就是由内核创建的了，这个文件中都是二进制0.然后如果可以的话，直接将内存中的该页写为二进制0.这样磁盘和主存之间没有数据传送
    无论那种情况，一旦一个虚拟页被创建了，它就在一个由内核维护的专门的交换文件（swap file）之间换来换去。任何时刻，交换空间都限制着当前进程能够分配的虚拟页面数目。

交换空间 交换空间swap space是啥？

14.内存映射和共享对象
  进程这一抽象可以为每个进程提供独立的私有虚拟内存空间，但是有时候有些数据是多个进程共用的。例如程序包含的库文件，系统调用。如果每个进程都在物理内存中保留它们的副本，那太占用内存了。
  一个对象如果可以被映射到虚拟内存中的一个区域，要么作为共享对象，要么作为私有对象。

  如果一个对象被映射为共享对象，那么共享该对象的进程都可以看到这个对象的改动。
  如果一个对象被映射为私有对象，那么该对象只对它所在的进程可见。
  每个对象都有唯一的文件名，所以内核可以快速判定进程1已经映射了这个对象。（文件系统这里还没看呢呀）

15.私有对象的写时复制 copy-on-write
  如果两个进程创建时有一个相同的私有对象，比如两个进程都调用了同一个库，但是都设置为私有的。
  那么在物理内存中只会有一个私有对象真实存在，只有当其中一个进程要对一个私有区域的某个页面时，就会触发一个保护故障。如果保护故障程序发现保护异常是由于进程对私有写时复制区域进行修改引起的，那就将该对象在物理内存中创建一个新的副本。这样做还是为了充分利用稀有的内存资源。

 动态内存分配
  1.低级的mmap和munmap可以动态的创建和删除虚拟内存区域。但是使用动态内存分配器更方便内存管理。动态内存分配器维护着一个进程的虚拟内存区域，称之为堆。堆紧接着.bss开始，向上生长。对于每个进程，内核维护着一个变量brk，它指向堆顶。堆定以上是共享库的内存映射区，再上面是栈。分配器将堆视为一组不同大小的块block的集合，每个块都是一个连续的虚拟内存空间，要么是已经分配的，要么是空闲的。
  分配器有两种实现风格：
    显式分配器：要求应用显式的释放任何已经分配的块。C标准库提供malloc和free函数来分配和释放block。c++中的new和free于此相当。
    隐式分配器：要求分配器检测什么时候这个block不再使用，那么就释放这个块。所以隐式分配器也称之为垃圾收集器，而自动释放块的过程称之为垃圾回收。java等高级语言就依赖的垃圾回收机制。OC也是哎。
  malloc函数，输入size，返回一个指针，指向大小为size的块。如果没有足够的内存空间，就返回null。malloc不初始化内存块，只返回地址。
  calloc初始化内存块。
  free函数释放已经分配的内存块，但是free没有返回值，只是根据输入地址释放，所以如果输入地址不当，可能会有难以预料的错误。
  2.碎片
  碎片使得堆的利用率降低。
  内部碎片：指的是block块内的碎片，分配的块比请求的块大，就会产生碎片。对齐是一个原因。
  外部碎片：当空闲碎片合计可以满足一个新的分配请求，但是

16. 再看fork函数
  fork函数调用一次，返回两次。返回给父进程子进程的PID。返回给子进程0。如果出现错误，就返回一个负值。
  fork出的子进程会完全复制父进程当前的状态，所以它被创建后会和父进程同步继续执行下去。

  当fork函数被当前进程调用后，内核会为新的进程创建各种数据结构，并分配给它一个唯一的PID（进程标识符，process ID）。它创建了当前进程的mm_struct,区域结构和页表的原样副本。它将两个进程的每个页面都标记为只读，并将两个进程中的每个私有区域都标记为写时复制。
  当fork函数在新的子进程返回时，新进程现在的虚拟内存刚好和调用fork时存在的虚拟内存相同。当两个进程中的任意一个对私有区域进行写操作时，写时复制机制就会在物理内存中创建新页面。

17. 再看execve函数
  execve函数在当前进程中加载并运行包含在可执行目标文件a.out，用a.out有效地替代了当前程序。加载并运行a.out需要如下步骤：
    删除已经存在的用户区域。删除当前进程虚拟地址的用户部分中已经存在的区域结构。
    映射私有区域。为新程序的代码，数据，bss和栈区域创建新的区域结构。所有的这些新的区域都是私有的，写时复制的。
    映射共享区域。如果a.out与共享对象链接，那么这些对象就会动态的链接到这个程序，然后在映射到用户虚拟地址空间中的共享区域。
    设置程序计数器。execve做的最后一件事就是设置当前进程上下文的程序计数器，这样子进程和父进程就同步执行了。

18. 使用mmap函数的用户级内存映射
  Linux进程可以使用mmap函数来创建新的虚拟内存区域，并将对象映射到这些区域中。

15. 共享对象

15.Linux的虚拟内存系统
  系统为每个进程都维护一个单独的虚拟内存空间，从0x4000 0000开始是：代码段.text，静态存储区和全局变量.data，未初始化的数据.bss, heap堆（进程调用malloc分配内存的时候，新的内存就分配到堆上），共享内存区（默认大小是32M），stack栈（用户创建的局部变量），内核代码和数据，物理内存，与进程相关的数据结构，如页表等。


16. Linux的缺页异常处理



9.虚拟内存作为保护内存的工具
  通过PTE的上的限制，比如在PTE上加上额外的许可位来限制进程的访问。SUP表示只有内核才能访问，READ和WRITE位表示读写权限。
  如果一个进程违反了这个许可条件，就会触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。shell一般将这中异常报告为“段错误”。
10.地址翻译
  1）处理器产生一个虚拟地址，将它传递给MMU。
    实际上对于处理器来将，它不知道这个地址是不是虚拟的，它只负责要一个地址的数据。但是这个地址是不是有效的那是虚拟内存机制的来处理的。
  2）MMU（内存管理单元）生成PTE地址，并向主存请求得到它。其实就是MMU查阅页表。
  3）主存将PTE返回给MMU。查阅页表成功了。
  4）MMU根据PTE构造物理地址，并从主存中读取这个地址里的数据。   这一步要是缺页了，就会触发异常。那cpu就执行中断程序了，那是另一个程序逻辑了，我们不用理会。反正最后，主存要载入这一页的数据。
  5）主存将数据传递给cpu。

11.利用TLB（翻译后备缓冲器）
  CPU每调用一次主存中的数据，MMU就要在主存中查阅一次PTE，PTE数据量很小，但是MMU访问主存这个时间相比CPU的时钟周期太慢了。所以通常在SRAM（L1）中有一个PTE的缓存区，因为SRAM是比主存还要高速的设备，所以减少了频繁的访问主存，而只为了一条PTE数据。



1.Linux下一个进程可以开多少线程
  取决于设定的线程最小栈空间大小
  32位linux系统最大内存地址4G，0-3GB的给用户进程(User Space)使用，3-4GB给内核使用
　stack size (kbytes,-s)10240表示线程堆栈大小,3G/10M=最大线程数，
