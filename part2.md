# mingOS
### 系统的虚拟内存实现
### 配合《深入理解计算机系统》食用

---------------
### part2 开始分页

那么开始构建关于页面管理的数据结构吧！

页表条目 PTE
```c
//页表条目PTE的定义 一个页表条目应该是32bit（在32位系统中）
typedef struct page
{
   u32int present    : 1;   // Page present in memory
   u32int rw         : 1;   // Read-only if clear, readwrite if set
   u32int user       : 1;   // Supervisor level only if clear
   u32int accessed   : 1;   // Has the page been accessed since last refresh?
   u32int dirty      : 1;   // Has the page been written to since last refresh?
   u32int unused     : 7;   // Amalgamation of unused and reserved bits
   u32int frame      : 20;  // Frame address (shifted right 12 bits)
} page_t;

//二级页表，每个二级页表中保存着1024个页表条目，那么一张二级页表就映射了1024*4KB=4MB的空间
typedef struct page_table
{
   page_t pages[1024];
} page_table_t;

//一级页表，每个一级页表中保存着1024张二级页表，那么一张一级页表就正好映射了4GB的内存空间，可是我们仅仅管理512MB的空间，那就是128
//page_directory里有两个数组，
//physicalAddr用于页目录复制或者切换进程时切换页目录。
typedef struct page_directory
{

   // Array of pointers to pagetables.
   page_table_t * tables[128];

   //Array of pointers to the pagetables above, but gives their physical location, for loading into the CR3 register.
   u32int tablesPhysical[128];

    // The physical address of tablesPhysical. This comes into play
    // when we get our kernel heap allocated and the directory
    // may be in a different location in virtual memory.
   u32int physicalAddr;
} page_directory_t;
```

在 void initialise_paging() 中首先要给要映射的内存空间的页表开辟内存。
```c
// The size of physical memory.
uint32_t mem_end_page = PMM_END_ADDR;
nframes = mem_end_page / PMM_PAGE_SIZE;
frames = (uint32_t*)kmalloc(INDEX_FROM_BIT(nframes));
memory_set(frames, 0, INDEX_FROM_BIT(nframes));
```
然后给kernel_directory页目录分配物理内存空间。
```c
kernel_directory = (page_directory_t*)kmalloc_a(sizeof(page_directory_t));//为页目录分配空间
memory_set(kernel_directory, 0, sizeof(page_directory_t));
current_directory = kernel_directory;
```

```c
int i = 0;
while (i < PMM_END_ADDR)//这里一定要用PMM_END_ADDR，PMM_END_ADDR是我们设定的mem_end_page的大小。对kernel_directory进行初始化一定要将全部页面初始化。否则系统不断重启。
{
    // Kernel code is readable but not writeable from userspace.
    alloc_frame( get_page(i, 1, kernel_directory), 0, 0);
    i += PMM_PAGE_SIZE;
}
// Before we enable paging, we must register our page fault handler.
register_interrupt_handler(IRQ14, page_fault);

// Now, enable paging!
switch_page_directory(kernel_directory);
```

然后再把0~PMM_END_ADDR的内存空间都在kernel_directory中做好映射。PMM_END_ADDR是我们在pmm.h中设定的一个最大内存空间，我设定的是512MB。
这里有一个困扰我两天的bug，开始我设定PMM_END_ADDR为内核占用的地址结束位置kern_end。这样是不行的。至少在我们目前的代码上不行，一旦将cr0的分页标志位置1后，系统会不断重启。这是因为 https://stackoverflow.com/questions/38157968/qemu-triple-faults-when-enabling-paging
一定要将kernel_directory的全部页面都初始化。设定缺页异常的中断向量号是IRQ14。然后switch_page_directory将cr3寄存器保存为kernel_directory的物理地址，并且将cr0更改开启分页模式。


在kernel_main中，我们可以试一下分页后的情况。我们设定的分页的内存最高地址是PMM_END_ADDR=0x20000000。
```c
//开启分页
initialise_paging();
clear_screen();

kprint("Hello, paging world!\n");
uint32_t *ptr = (uint32_t*)0x1E000000;
uint32_t do_page_fault = *ptr;
```
如果你把ptr这个指针的值设置成超过0x20000000会怎样呢？那就触发了缺页中断，并且永远无法有新的内存分配进来，就会一直在缺页中断里。

不过我还有一个bug没有解决，就是在开启分页后，显卡缓冲区的数据就突然变成了乱码。然后整个屏幕就充斥着乱码符号。但是不影响目前的系统使用，后面清下屏幕就好了。

尽管我们开启了分页，也有了页目录和页表，但是这些还不是虚拟内存，因为我们没有把内存中的页保存在磁盘中。也就是说，内存没有作为磁盘的缓存。

---------------
### 内存管理的解决办法-虚拟内存
在保护模式下, 寄存器CR0的高位1表示开启分页.0表示不开启.

1. 虚拟内存
  为了更高效的管理多进程系统的内存。它为每一个进程提供一个大的，一致的私有的空间。
  虚拟内存提供了三种能力：
    1）将主存看作是磁盘地址空间的一个高速缓存，在主存中只保留活动区域
    2）它为每个进程提供了一致的地址空间，简化内存管理
    3）保护每个进程之间的地址空间独立，互相不破坏

2. 具体分页实现

  1). 内存分页：

      将物理内存空间分割为4kb大小的页，32位机器可以寻址2^32=4GB内存空间。将4GB空间划分为4KB大小的页，一共可分为的页数为：1MB

  2). 页表条目（page table entry，PTE）

      用一个unit32型变量（4个字节）来保存每一页的起始地址，这就是页表条目。

      但是我们的页是4K对齐的，所以这个32bit的变量的低12位总是0.保存在PTE里什么作用都不起太浪费了，那就用这12bit作为有效位吧。

  3). 页表

      将每个PTE保存在一个数组里，这就是页表。我们需要访问那一段内存的时候，就通过查询页表访问。

      用一个unit32型变量（4个字节）保存这个每一页的起始地址，一张页表映射4MB的内存空间。那么一张页表本身的大小就是

  4). PDT Page Directory Entry
      和PTE概念类似，保存着页表地址。

  5). 页目录
      保存PDT的数组。页目录的地址由CR3寄存器保存。这样可以快速找到页目录地址，比在内存中访问要快上百倍。

首先我们一定要区分虚拟内存和物理内存。在本节我一定在每一个地方都用这两个词，而不是用“内存”。
为了为每个应用程序提供相同的“4GB内存”，我们需要利用磁盘，在磁盘上一定有这么大的空间容纳我们分配的n*4GB的空间。
而物理内存将作为磁盘的缓存。再次强调，构建虚拟内存是提供给用户模式的应用程序使用的。我们为物理内存构建一张表格，表格中记录了每一页物理内存的起始地址。

一级页表中的每个PTE负责映射虚拟地址空间的一个4MB的片，每一片中有1024个连续的页。二级页表中的每个PTE负责映射虚拟地址空间的一个4kB的页。具体到实际的32位的地址寻址上，一级页表条目保存着高10位，对应着1024个4MB空间；二级页表保存着中间10位，对应着1024个4KB空间；剩下的12位正好代表4kb的地址偏移量。如果一级页表中的某一片是空的，那么二级页表就不会存在。只有一级页表需要总是存在主存中，频繁使用的二级页表缓存在主存中。这就是为何要使用二级页表的原因，完全是为了不要让4MB的页表一直占用物理内存空间。

那么当一个进程想要使用某一页虚拟内存的时候，比如说0x10000~0x11000这一页。系统怎样将这一页的内容传递给进程呢？
寻址过程：虚拟地址/0x1000=页表序号。 页序号/1024就是页目录PDT中第几个条目。找到这个页目录条目中保存的的物理地址就是页表的地址。（虚拟地址/0x1000）/0x1000就是PTE序号。读取PTE的20bit物理地址左移12bit，就是物理地址了。

cr0寄存器的高位用来开启分页。

还是要从平坦模型说起。既然我们不采用分段的内存管理模式了，那么整个4GB内存就被看成是一段。这里的内存指的是物理主存。哎，脑壳疼。系统要为每一个进程创建对应的页表和页目录。进程基于系统的虚拟内存这一抽象，它无需考虑具体的物理地址。那么对每个进程而言，它可以访问的地址当然从头开始比较方便呀。所以虚拟内存中，0-3GB的地址空间就划分给进程了。但是如果你从头写过操作系统就一定知道，最开始系统内核其实是在物理内存的低位置处的。Linux采用的页面管理方案是：内核映射到线性地址3GB以上空间，而应用程序占据线性地址空间的0-3GB位置。但是我暂时不打算这样做了，因为最近时间真的很紧张，以后再看看吧。

这一部分我们要在part1的基础上实现虚拟内存的页面映射功能。不知道今晚上可不可以搞完，但是很想快点搞定。果然没搞完哈哈。




1.虚拟内存作为缓存的工具 磁盘作为主存的缓存
  我们将磁盘中某一段区域也分割称4kb大小的页，将主存中不活跃的页暂存在磁盘中，主存中保存这活跃的页。这样可以最大限度的利用有限的主存，让更多进程时刻调用的页保持在主存中。

  这里要注意下，由于磁盘的构造。他随机读取一个字节的代价非常高昂。而且往往在使用一段信息的时候，它的上下文也是有可能在下一时刻被使用。数据库的B-tree就是这样设计的嘛。所以对磁盘一次仅仅读取一个字节不合理。所以我们一般将页设计成4kb～2MB。

  我们认为设定了一个概念，虚拟内存。这个虚拟内存被组织为一个存在磁盘中的数组，数组的每一个字节都有一个唯一的虚拟地址，作为数组的索引。
  磁盘上的这个数组，活跃部分被缓存到主存中。
  这个数组被分割成块，主存和磁盘之间的传输最小单位就是块。实际上就是虚拟内存的页。
  虚拟内存系统将虚拟内存分割为虚拟页，每一页大小是P字节。对应物理内存也得分成物理页，这是方便我们载入页到实际的主存中。
  那么虚拟内存的全部页可以分为三种情况：
    1）未分配的
    2）缓存的
    3）未缓存的

2.虚拟内存作为内存管理工具带来的好处
  1）简化了链接：因为在虚拟内存中，每个进程有自己独立的内存空间，这个内存空间的真实地址由系统和CPU的内存管理单元翻译。
  所以链接的时候不需要考虑程序在主存中的真实地址是多少，只要将每个程序按照相同的格式翻译好就可以了。
  比如，链接器对不同的程序，总是可以设置成代码段从0x400000开始，静态数据段跟在代码段之后，然后是堆，从高地址往下是栈。
  这样的一致性对于链接器来讲实在是太方便了，我们终于看到系统带来的巨大好处。
  它将内存地址这种具体的硬件抽象，对于上层的应用而言，不用针对设备具体设计程序。
  2）简化加载：Linux系统加载器加载可执行文件的时候，只需要为代码段和数据段分配虚拟页，把他们标记为无效的（未缓存的）就可以了。这时候他们还在磁盘上，只有系统调用该页的时候，产生了缺页异常，系统才会加载该页到主存。这样看来，还是系统帮我们解决了和硬件打交道的工作，我们编写的程序只需要满足系统指定的规则就可以了。
  将一组连续虚拟页映射到一个文件的任意位置，叫做内存映射。Linux提供一个mmap的系统调用，允许应用程序自己做内存映射。
  3）简化共享：如果多个进程都需要调用一些系统代码，系统调用。那么操作系统就可以将不同进程中的适当虚拟页映射到相同的物理页上（它们共同调用的那些系统代码段）。
  4）简化内存分配：

  虚拟内存作为保护内存的工具
    通过PTE的上的限制，比如在PTE上加上额外的许可位来限制进程的访问。SUP表示只有内核才能访问，READ和WRITE位表示读写权限。
    如果一个进程违反了这个许可条件，就会触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。shell一般将这中异常报告为“段错误”。

3.缺页
  缺页异常，当CPU引用某一页的VP3，但是在页表PTE3中发现它的有效位是0。说明这一页没有加载到DRAM中，那就需要从磁盘中加载这一页。
  于是触发系统缺页异常，异常处理程序会在主存中选择一个牺牲页VP4。如果该牺牲页已经被修改了(和磁盘中的相比)，那就将它复制回磁盘。
  接下来内核会从磁盘中复制VP3到内存中的pp3中。这就完成了缺页的处理。
  页从磁盘和主存之间的传送叫做页面调度，一般都是用按需调度，只有在不明中的时候才调度。

4.程序的局部性保证了缺页异常不会经常发生，从而保证了虚拟内存的高效率。
  虚拟内存是用低速的磁盘作为主存的拓展，如果频繁的发生页面调度，那么肯定会拉低程序的运行效率。
  但是进程在执行过程中并不是频繁的跳来跳去的，因为cpu只能执行当前代码段，所以它访问的虚拟内存的页也是有限的。
  如果我我们不引入虚拟内存，那么多进程的内存管理实在是太麻烦了。程序执行效率肯定一定会更低，除非你有比虚拟内存更好的办法。

  程序运行时，短时间内总是趋向于在一个较小的活动页面集合上工作，这个集合叫做工作集，或者常驻集合。
  如果工作集超过了物理内存的大小，那程序将处于一种“抖动状态”，页面将频繁的调度。
  这时候就效率太低了，是不是程序设计的太不合理了，一次读取了太大的数据。



5.内存映射
  Linux系统将一个虚拟内存区域与一个磁盘上的对象关联
  虚拟内存区域可以映射到两种类型的文件中的一种：
    1）Linux文件系统中的普通文件，这种情况下只是将PTE更改了，但是磁盘上的文件没有真正复制到主存中，只有cpu访问该文件触发缺页异常后，才载入主存。
    2）匿名文件，映射到匿名文件时，这个就是由内核创建的了，这个文件中都是二进制0.然后如果可以的话，直接将内存中的该页写为二进制0.这样磁盘和主存之间没有数据传送
    无论那种情况，一旦一个虚拟页被创建了，它就在一个由内核维护的专门的交换文件（swap file）之间换来换去。任何时刻，交换空间都限制着当前进程能够分配的虚拟页面数目。

交换空间 交换空间swap space是啥？

6.内存映射和共享对象
  进程这一抽象可以为每个进程提供独立的私有虚拟内存空间，但是有时候有些数据是多个进程共用的。例如程序包含的库文件，系统调用。如果每个进程都在物理内存中保留它们的副本，那太占用内存了。
  一个对象如果可以被映射到虚拟内存中的一个区域，要么作为共享对象，要么作为私有对象。

  如果一个对象被映射为共享对象，那么共享该对象的进程都可以看到这个对象的改动。
  如果一个对象被映射为私有对象，那么该对象只对它所在的进程可见。
  每个对象都有唯一的文件名，所以内核可以快速判定进程1已经映射了这个对象。（文件系统这里还没看呢呀）

7.私有对象的写时复制 copy-on-write
  如果两个进程创建时有一个相同的私有对象，比如两个进程都调用了同一个库，但是都设置为私有的。
  那么在物理内存中只会有一个私有对象真实存在，只有当其中一个进程要对一个私有区域的某个页面时，就会触发一个保护故障。如果保护故障程序发现保护异常是由于进程对私有写时复制区域进行修改引起的，那就将该对象在物理内存中创建一个新的副本。这样做还是为了充分利用稀有的内存资源。


10.地址翻译
  1）处理器产生一个虚拟地址，将它传递给MMU。
    实际上对于处理器来将，它不知道这个地址是不是虚拟的，它只负责要一个地址的数据。但是这个地址是不是有效的那是虚拟内存机制的来处理的。
  2）MMU（内存管理单元）生成PTE地址，并向主存请求得到它。其实就是MMU查阅页表。
  3）主存将PTE返回给MMU。查阅页表成功了。
  4）MMU根据PTE构造物理地址，并从主存中读取这个地址里的数据。   这一步要是缺页了，就会触发异常。那cpu就执行中断程序了，那是另一个程序逻辑了，我们不用理会。反正最后，主存要载入这一页的数据。
  5）主存将数据传递给cpu。

11.利用TLB（翻译后备缓冲器）
  CPU每调用一次主存中的数据，MMU就要在主存中查阅一次PTE，PTE数据量很小，但是MMU访问主存这个时间相比CPU的时钟周期太慢了。所以通常在SRAM（L1）中有一个PTE的缓存区，因为SRAM是比主存还要高速的设备，所以减少了频繁的访问主存，而只为了一条PTE数据。
